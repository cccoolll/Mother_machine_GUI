# -*- coding: utf-8 -*-

# Form implementation generated from reading ui file 'delta_GUI.ui'
#
# Created by: PyQt5 UI code generator 5.15.2
#
# WARNING: Any manual changes made to this file will be lost when pyuic5 is
# run again.  Do not edit this file unless you know what you are doing.

import sys
from PyQt5 import QtCore, QtGui, QtWidgets
from PyQt5.QtWidgets import QApplication, QMainWindow, QMessageBox, QInputDialog, QFileDialog, QGridLayout
#import pyqtgraph as pg
import numpy as np
import matplotlib.pyplot as plt
import math
from PyQt5.QtGui import QPixmap
import matplotlib as mpl
import os
from matplotlib.backends.backend_qt5agg import FigureCanvasQTAgg as FigureCanvas
from matplotlib.figure import Figure
import time

class Ui_Form(object):
    def setupUi(self, Form):
        Form.setObjectName("Form")
        Form.resize(1714, 989)
        self.tabWidget = QtWidgets.QTabWidget(Form)
        self.tabWidget.setGeometry(QtCore.QRect(360, 80, 1341, 761))
        self.tabWidget.setObjectName("tabWidget")
        self.tab = QtWidgets.QWidget()
        self.tab.setObjectName("tab")
        self.widget = QtWidgets.QWidget(self.tab)
        self.widget.setGeometry(QtCore.QRect(150, 0, 811, 641))
        self.widget.setObjectName("widget")
        self.groupBox = QtWidgets.QGroupBox(self.widget)
        self.groupBox.setGeometry(QtCore.QRect(10, 0, 801, 641))
        self.groupBox.setObjectName("groupBox")
        self.tabWidget.addTab(self.tab, "")
        self.tab_2 = QtWidgets.QWidget()
        self.tab_2.setObjectName("tab_2")
        self.widget_2 = QtWidgets.QWidget(self.tab_2)
        self.widget_2.setGeometry(QtCore.QRect(10, 30, 571, 561))
        self.widget_2.setObjectName("widget_2")
        self.groupBox_2 = QtWidgets.QGroupBox(self.widget_2)
        self.groupBox_2.setGeometry(QtCore.QRect(10, 0, 551, 551))
        self.groupBox_2.setObjectName("groupBox_2")
        self.widget_3 = QtWidgets.QWidget(self.tab_2)
        self.widget_3.setGeometry(QtCore.QRect(600, 30, 571, 561))
        self.widget_3.setObjectName("widget_3")
        self.groupBox_3 = QtWidgets.QGroupBox(self.widget_3)
        self.groupBox_3.setGeometry(QtCore.QRect(10, 0, 551, 551))
        self.groupBox_3.setObjectName("groupBox_3")
        self.tabWidget.addTab(self.tab_2, "")
        self.Tab_3 = QtWidgets.QWidget()
        self.Tab_3.setObjectName("Tab_3")
        self.widget_4 = QtWidgets.QWidget(self.Tab_3)
        self.widget_4.setGeometry(QtCore.QRect(10, 40, 1311, 641))
        self.widget_4.setObjectName("widget_4")
        self.groupBox_4 = QtWidgets.QGroupBox(self.widget_4)
        self.groupBox_4.setGeometry(QtCore.QRect(10, 10, 2000, 611))
        self.groupBox_4.setTitle("")
        self.groupBox_4.setObjectName("groupBox_4")
        self.comboBox_3 = QtWidgets.QComboBox(self.Tab_3)
        self.comboBox_3.setGeometry(QtCore.QRect(130, 10, 87, 22))
        self.comboBox_3.setObjectName("comboBox_3")
        self.horizontalScrollBar = QtWidgets.QScrollBar(self.Tab_3)
        self.horizontalScrollBar.setGeometry(QtCore.QRect(550, 10, 271, 21))
        self.horizontalScrollBar.setOrientation(QtCore.Qt.Horizontal)
        self.horizontalScrollBar.setObjectName("horizontalScrollBar")
        self.tabWidget.addTab(self.Tab_3, "")
        self.pushButton = QtWidgets.QPushButton(Form)
        self.pushButton.setGeometry(QtCore.QRect(80, 420, 141, 31))
        self.pushButton.setObjectName("pushButton")
        self.textBrowser = QtWidgets.QTextBrowser(Form)
        self.textBrowser.setGeometry(QtCore.QRect(80, 350, 261, 31))
        self.textBrowser.setObjectName("textBrowser")
        self.textBrowser_2 = QtWidgets.QTextBrowser(Form)
        self.textBrowser_2.setGeometry(QtCore.QRect(10, 850, 1181, 121))
        self.textBrowser_2.setObjectName("textBrowser_2")
        self.pushButton_2 = QtWidgets.QPushButton(Form)
        self.pushButton_2.setGeometry(QtCore.QRect(240, 420, 101, 31))
        self.pushButton_2.setObjectName("pushButton_2")
        self.textBrowser_3 = QtWidgets.QTextBrowser(Form)
        self.textBrowser_3.setGeometry(QtCore.QRect(80, 50, 261, 31))
        self.textBrowser_3.setObjectName("textBrowser_3")
        self.textBrowser_4 = QtWidgets.QTextBrowser(Form)
        self.textBrowser_4.setGeometry(QtCore.QRect(80, 150, 261, 31))
        self.textBrowser_4.setObjectName("textBrowser_4")
        self.pushButton_4 = QtWidgets.QPushButton(Form)
        self.pushButton_4.setGeometry(QtCore.QRect(80, 100, 261, 31))
        self.pushButton_4.setObjectName("pushButton_4")
        self.pushButton_6 = QtWidgets.QPushButton(Form)
        self.pushButton_6.setGeometry(QtCore.QRect(80, 190, 261, 31))
        self.pushButton_6.setObjectName("pushButton_6")
        self.label_3 = QtWidgets.QLabel(Form)
        self.label_3.setGeometry(QtCore.QRect(70, 280, 145, 21))
        self.label_3.setObjectName("label_3")
        self.label_4 = QtWidgets.QLabel(Form)
        self.label_4.setGeometry(QtCore.QRect(320, 280, 31, 16))
        self.label_4.setObjectName("label_4")
        self.textEdit = QtWidgets.QTextEdit(Form)
        self.textEdit.setGeometry(QtCore.QRect(230, 270, 71, 31))
        self.textEdit.setObjectName("textEdit")
        self.label = QtWidgets.QLabel(Form)
        self.label.setGeometry(QtCore.QRect(640, 20, 72, 15))
        self.label.setObjectName("label")
        self.comboBox_2 = QtWidgets.QComboBox(Form)
        self.comboBox_2.setGeometry(QtCore.QRect(770, 51, 251, 31))
        self.comboBox_2.setObjectName("comboBox_2")
        self.comboBox = QtWidgets.QComboBox(Form)
        self.comboBox.setGeometry(QtCore.QRect(630, 51, 101, 31))
        self.comboBox.setObjectName("comboBox")
        self.label_2 = QtWidgets.QLabel(Form)
        self.label_2.setGeometry(QtCore.QRect(770, 20, 72, 15))
        self.label_2.setObjectName("label_2")

        self.retranslateUi(Form)
        self.tabWidget.setCurrentIndex(2)
        QtCore.QMetaObject.connectSlotsByName(Form)

    def retranslateUi(self, Form):
        _translate = QtCore.QCoreApplication.translate
        Form.setWindowTitle(_translate("Form", "Form"))
        self.groupBox.setTitle(_translate("Form", "Chamber segmentation"))
        self.tabWidget.setTabText(self.tabWidget.indexOf(self.tab), _translate("Form", "Tab 1"))
        self.groupBox_2.setTitle(_translate("Form", "Fluorescent"))
        self.groupBox_3.setTitle(_translate("Form", "Cell length"))
        self.tabWidget.setTabText(self.tabWidget.indexOf(self.tab_2), _translate("Form", "Tab 2"))
        self.tabWidget.setTabText(self.tabWidget.indexOf(self.Tab_3), _translate("Form", "Tab3"))
        self.pushButton.setText(_translate("Form", "Select Folder"))
        self.pushButton_2.setText(_translate("Form", "Run"))
        self.pushButton_4.setText(_translate("Form", "Select model of chamber"))
        self.pushButton_6.setText(_translate("Form", "Select model of segmentation"))
        self.label_3.setText(_translate("Form", "GPU memory limit"))
        self.label_4.setText(_translate("Form", "GB"))
        self.label.setText(_translate("Form", "Fov"))
        self.label_2.setText(_translate("Form", "Chamber"))






class MyMainForm(QMainWindow,Ui_Form):
    def __init__(self,parent=None):
        super(MyMainForm,self).__init__(parent)
        self.setupUi(self)



        self.figure = Figure()  # 可选参数,facecolor为背景颜色
        self.canvas = FigureCanvas(self.figure)
        self.ax = self.figure.subplots()
        self.ax.set_axis_off()
        self.gridlayout = QGridLayout(self.groupBox)  # 继承容器groupBox
        self.gridlayout.addWidget(self.canvas)

        self.figure2 = Figure()  # 可选参数,facecolor为背景颜色
        self.canvas2 = FigureCanvas(self.figure2)
        self.ax2 = self.figure2.subplots()
        #self.ax2.set_axis_off()#不显示坐标
        self.gridlayout2 = QGridLayout(self.groupBox_2)  # 继承容器groupBox
        self.gridlayout2.addWidget(self.canvas2)

        self.figure3 = Figure()  # 可选参数,facecolor为背景颜色
        self.canvas3 = FigureCanvas(self.figure3)
        self.ax3 = self.figure3.subplots()
        #self.ax3.set_axis_off()
        self.gridlayout3 = QGridLayout(self.groupBox_3)  # 继承容器groupBox
        self.gridlayout3.addWidget(self.canvas3)

        self.figure4 = Figure()  # 可选参数,facecolor为背景颜色
        self.canvas4 = FigureCanvas(self.figure4)

        self.ax4 = self.figure4.subplots()
        self.ax4.set_axis_off()
        self.gridlayout4 = QGridLayout(self.groupBox_4)  # 继承容器groupBox
        self.gridlayout4.addWidget(self.canvas4)








        self.pushButton.clicked.connect(self.openfile_chamber)
        self.pushButton_2.clicked.connect(self.run_pipline)
        #self.comboBox.currentIndexChanged.connect(self.choose_Chamber)
        self.comboBox.activated.connect(self.choose_Chamber)
        self.comboBox_2.activated.connect(self.show_Chamber)
        self.pushButton_4.clicked.connect(self.select_chamber_model)
        self.pushButton_6.clicked.connect(self.select_seg_model)
        #self.pushButton_3.clicked.connect(self.show_movie)
        self.horizontalScrollBar.sliderMoved.connect(self.sliderMoved)
        self.x = self.groupBox_4.pos().x()
        # 由于是控制groupbox的x轴数值，为方便后面使用，所以提前修改。
        self.comboBox_3.activated.connect(self.show_movie)




    def sliderMoved(self):
        self.groupBox_4.move(self.x - self.horizontalScrollBar.value()*20, 0)


    def converttime(time):
        h, s = divmod(time, 60 * 60)
        m, s = divmod(s, 60)
        h = h + m / 60 + s / 3600
        return h




    def openfile_chamber(self):
        get_directory_path = QFileDialog.getExistingDirectory(self,
                                                              "Select file folder")
        self.file_path=get_directory_path
        self.textBrowser_print(self.file_path)

        #self.F_seg.show_chamber_seg()

    def textBrowser_print(self,str):
        self.textBrowser.append(str)
        self.cursor=self.textBrowser.textCursor()
        self.textBrowser.moveCursor(self.cursor.End)
        QtWidgets.QApplication.processEvents()

    def textBrowser2_print(self,str):
        self.textBrowser_2.append(str)
        self.cursor=self.textBrowser_2.textCursor()
        self.textBrowser_2.moveCursor(self.cursor.End)
        QtWidgets.QApplication.processEvents()

    def textBrowser3_print(self,str):
        self.textBrowser_3.append(str)
        self.cursor=self.textBrowser_3.textCursor()
        self.textBrowser_3.moveCursor(self.cursor.End)
        QtWidgets.QApplication.processEvents()

    def textBrowser4_print(self,str):
        self.textBrowser_4.append(str)
        self.cursor=self.textBrowser_4.textCursor()
        self.textBrowser_4.moveCursor(self.cursor.End)
        QtWidgets.QApplication.processEvents()

    def textBrowser5_print(self,int):
        self.textBrowser_5.append(int)
        self.cursor=self.textBrowser_5.textCursor()
        self.textBrowser_5.moveCursor(self.cursor.End)
        QtWidgets.QApplication.processEvents()







    def choose_Chamber(self):
        text = self.comboBox.currentText()
        self.comboBox_2.clear()
        #self.comboBox_2.addItems(self.celllist[int(text)]['chamber'])
        #frommokeys 用来防止重复
        self.comboBox_2.addItems(list(dict.fromkeys(self.celllist[int(text)]['chamber'])))
        self.show_chamber_seg()

    def show_Chamber(self):
        text = str(self.comboBox_2.currentText())
        #plt.figure(figsize=(7, 5))
        #这两行命令是为了防止图片重叠
        self.ax2.set_axis_off()
        self.ax2 = self.figure2.subplots()

        self.ax2.scatter(self.chamberdict[text]['time_h'], self.chamberdict[text]['green_mean'], s=20, c="#66ff33",
                    marker='o')
        self.ax2.scatter(self.chamberdict[text]['time_h'], self.chamberdict[text]['red_mean'], s=20, c="#ff1212",
                    marker='v')
        #self.ax2.ylabel('Fluorescent')
        #self.ax2.xlabel('Time_hour')
        #self.ax2.imshow()
        self.canvas2.draw()

        self.show_Chamber_len()
        self.show_movie()

    def show_Chamber_len(self):
        text = str(self.comboBox_2.currentText())
        #这两行命令是为了防止图片重叠
        self.ax3.set_axis_off()
        self.ax3 = self.figure3.subplots()

        #plt.figure(figsize=(7, 5))
        self.ax3.plot(self.chamberdict[text]['time_h'], self.chamberdict[text]['length'])
        #self.ax3.ylabel('Cell Length')
        #self.ax3.xlabel('Time_hour')
        #plt.show()
        self.canvas3.draw()

    def show_chamber_seg(self):

        DIR=os.path.join(self.file_path,'chamber_load')
        file_name = os.listdir(DIR)
        file_name = [name for name in file_name if name.split('_')[-1] == 'chamber.png' ]
        file_name = [name for name in file_name if name.split('_')[-2] == str(self.comboBox.currentText())]
        import matplotlib.image as mpimg  # mpimg 用于读取图片
        f=os.path.join(DIR,file_name[0])
        im=mpimg.imread(f)
        self.ax.imshow(im)
        self.canvas.draw()
        self.ax.set_axis_off()



    def select_chamber_model(self):
        self.model_chamber_FN, fileType = QtWidgets.QFileDialog.getOpenFileName(self, "选取文件", os.getcwd(),
                                                                   "All Files(*);;Text Files(*.txt)")
        self.textBrowser3_print(self.model_chamber_FN)

    def select_seg_model(self):
        self.model_seg_FN, fileType = QtWidgets.QFileDialog.getOpenFileName(self, "选取文件", os.getcwd(),
                                                                              "All Files(*);;Text Files(*.txt)")
        self.textBrowser4_print(self.model_seg_FN)

    def show_movie(self):
        import numpy as np
        from joblib import load
        import momo_jl_analysis as mja
        DIR = self.file_path
        jl_file = mja.find_jl(DIR)
        fov_number= int(self.comboBox.currentText())
        fov_jl = load(jl_file[fov_number])
        text_cha = self.comboBox_2.currentText()

        ch_list = list(dict.fromkeys(self.celllist[int(fov_number)]['chamber']))
        ch=ch_list.index(str(text_cha))

        time=[0,len(fov_jl['times']['green'])]
        GREEN_COLOR = (0, 255, 0)  # RGB
        RED_COLOR = (255, 0, 0)  # RGB
        #防止图片重叠
        self.ax4.set_axis_off()
        self.ax4 = self.figure4.subplots()
        if str(self.comboBox_3.currentText()) == 'Merge':

            ims_with_cnt_green = mja.draw_contour(ch=ch,channel='green',time=time,fov_jl=fov_jl,
                                                  color=GREEN_COLOR, threshold=600, contours=False)
            ims_with_cnt_red = mja.draw_contour(ch=ch, channel='red', time=time, fov_jl=fov_jl,
                                                color=RED_COLOR, threshold=800, contours=False)

            ims_with_cnt = ims_with_cnt_green ** 0.32 + ims_with_cnt_red ** 0.32  # nonlinear rescale

        elif str(self.comboBox_3.currentText()) == 'Phase':
            ims_with_cnt_phase = mja.draw_contour(ch=ch, channel='phase', time=time, fov_jl=fov_jl,
                                                  threshold=0, contours=False)
            ims_with_cnt = ims_with_cnt_phase# nonlinear rescale
        elif str(self.comboBox_3.currentText()) == 'Red':
            ims_with_cnt_red = mja.draw_contour(ch=ch, channel='red', time=time, fov_jl=fov_jl,
                                                  color=RED_COLOR, threshold=800, contours=False)
            ims_with_cnt =  ims_with_cnt_red ** 0.32  # nonlinear rescale
        elif str(self.comboBox_3.currentText()) == 'Green':
            ims_with_cnt_green = mja.draw_contour(ch=ch, channel='green', time=time, fov_jl=fov_jl,
                                                  color=GREEN_COLOR, threshold=600, contours=False)
            ims_with_cnt = ims_with_cnt_green ** 0.32  # nonlinear rescale

        self.ax4.set_axis_off()
        self.ax4 = self.figure4.subplots()
        self.ax4.imshow(mja.rangescale(ims_with_cnt, (0, 255)).astype(np.uint8))
        self.ax4.grid(False)
        self.canvas4.draw()















    def run_pipline(self):
        self.textBrowser2_print('Loading environment........\nnotice:Delete the export files before you rerun')
        self.comboBox_2.addItem('Choose when finished')
        self.comboBox_3.addItems(['Merge', 'Phase', 'Green', 'Red'])
        # Built-in/Generic Imports
        import os
        # Libs
        import pandas as pd
        # Own modules
        from joblib import dump
        import dask
        from dask.diagnostics import ProgressBar
        from tqdm import tqdm
        import _thread as thread
        import time
        # Built-in/Generic Imports
        import os
        import sys
        # […]

        # Libs
        import pandas as pd
        import numpy as np  # Or any other
        from tqdm import tqdm

        import time
        # […]

        # Own modules
        from utils.delta.data import postprocess
        from utils.delta.model import unet_chambers, unet_seg
        import numpy as np

        import tensorflow as tf
        import cv2
        import tifffile as tif
        from utils.delta.utilities import getChamberBoxes, getDriftTemplate, driftcorr, rangescale, cropbox
        from joblib import Parallel, dump, delayed
        from utils.rotation import rotate_fov, rotate_image
        from utils.signal import vertical_mean
        from scipy.fftpack import fft, fftfreq
        from matplotlib.patches import Rectangle

        # import dask
        # # dask.config.set(pool=ThreadPool(64))
        # from dask.distributed import Client, progress
        # from dask.diagnostics import ProgressBar
        # client = Client(threads_per_worker=64, n_workers=1)

        # Allow memory growth for the GPU
        # physical_devices = tf.config.experimental.list_physical_devices('GPU')
        # tf.config.experimental.set_memory_growth(physical_devices[0], True)
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            # Restrict TensorFlow to only allocate 1GB of memory on the first GPU
            try:
                tf.config.experimental.set_virtual_device_configuration(
                    gpus[0],
                    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=int(self.textEdit.toPlainText()) * 1024)])
                logical_gpus = tf.config.experimental.list_logical_devices('GPU')
                print(len(gpus), "Physical GPUs,", len(logical_gpus), "Logical GPUs")
            except RuntimeError as e:
                # Virtual devices must be set before GPUs have been initialized
                print(e)

        model_file = self.model_chamber_FN
        seg_model_file = self.model_seg_FN
        min_chamber_area = 3e3
        target_size = (512, 512)
        input_size = target_size + (1,)
        process_size = 200
        model_chambers = unet_chambers(input_size=input_size)
        model_chambers.load_weights(model_file)
        target_size_seg = (256, 32)
        model_seg = unet_seg(input_size=target_size_seg + (1,))
        model_seg.load_weights(seg_model_file)

        def get_channel_name(dir, name):
            return os.listdir(os.path.join(dir, name))

        def box_2_pltrec(box):
            plt_x, plt_y = box['xtl'], box['ytl']
            h = int(box['ybr'] - box['ytl'])
            w = int(box['xbr'] - box['xtl'])
            return dict(xy=(plt_x, plt_y), width=w, height=h)

        def draw_channel_order(im, chn_boxs, colors, ax=None):
            if ax == None:
                ax = plt.gca()
            ax.imshow(im, cmap='gray')
            for i, box in enumerate(chn_boxs):
                ax.add_patch(Rectangle(**box_2_pltrec(box), fill=False, edgecolor=colors[i]))
            return ax

        def get_times(dir, name, channels):
            tim_dict = dict()
            for channel in channels:
                file_name = os.listdir(os.path.join(dir, name, channel))
                file_name = [name for name in file_name if name.split('.')[-1] == 'tiff']
                file_name.sort(key=lambda elem: int(elem.split('.')[0][1:]))
                tim_dict[channel] = file_name
            return tim_dict

        def crop_images(imgs, box):
            """
            Crop images

            Parameters
            ----------
            imgs : 3D numpy array [t, x, y]
                Image to crop.
            box : Dictionary
                Dictionary describing the box to cut out, containing the following
                elements:
                    - 'xtl': Top-left corner X coordinate.
                    - 'ytl': Top-left corner Y coordinate.
                    - 'xbr': Bottom-right corner X coordinate.
                    - 'ybr': Bottom-right corner Y coordinate.

            Returns
            -------
            2D numpy array
                Cropped-out region.

            """
            return imgs[:, box['ytl']:box['ybr'], box['xtl']:box['xbr']]

        def back_corrt(im: np.ndarray) -> np.ndarray:
            im -= int(np.median(im))
            im[im < 0] = 0.
            return im

        def get_im_time(ps):
            with tif.TiffFile(ps) as tim:
                return tim.asarray(), tim.shaped_metadata[0]['time']

        def get_fluo_channel(ps, drift, angle, direct):
            im, time = get_im_time(ps)
            im = rotate_image(im, angle)
            if direct:
                im, _ = driftcorr(img=im, template=None, box=None, drift=drift)
            else:
                im, _ = driftcorr(img=im[::-1, :], template=None, box=None, drift=drift)
            return im, time

        def parallel_seg_input(ims, box, size=(256, 32)):
            """
            seg images and resized to a certain size.
            :param ims: frames
            :param box: chamberbox
            :param size: resize scale
            :return: resize images, un-resized images
            """

            def resize_map(i, size):
                resize_ims[i, ...] = cv2.resize(subims[i, ...], size[::-1])
                return None

            subims = ims[:, box['ytl']:box['ybr'], box['xtl']:box['xbr']]
            ims_num = len(subims)
            resize_ims = np.empty((ims_num,) + size)
            _ = Parallel(n_jobs=30, require='sharedmem')(delayed(resize_map)(im_inx, size) for im_inx in range(ims_num))
            return resize_ims, subims

        class MomoFov:
            def __init__(self, name, dir):
                """
                :param name: str, fov name eg. 'fov_0'
                :param dir: str, path of fovs
                """
                self.fov_name = name
                self.dir = dir
                self.cell_minisize = 100
                self.channels = get_channel_name(self.dir, self.fov_name)
                self.times = None
                self.phase_ims = None
                self.time_points = dict()
                self.chambermask = None
                self.chamberboxes = []
                self.loaded_chamber_box = []
                self.drifttemplate = None
                self.template_frame = None
                self.chamber_direction = None
                self.drift_values = None
                self.cell_mask = None  # NOTE: cell_mask have a order which is dependent on times. i.e. #chan_1 ---times----
                # #chan_2 --- times---
                self.chamber_cells_mask = dict()  # resized cells mask
                self.chamber_cells_contour = dict()
                self.loaded_chamber_name = []
                self.chamber_red_ims = dict()
                self.chamber_green_ims = dict()
                self.chamber_phase_ims = dict()
                self.mother_cell_pars = dict()
                self.dataframe_mother_cells = pd.DataFrame(data=[])
                self.index_of_loaded_chamber = []
                self.chamber_graylevel = []
                self.chamber_seg = None
                self.rotation = []
                self.colors_2 = ['#FFA2A8', '#95FF57']  # red, green

            def detect_channels(self, number=0):
                """
                The frame number used to detect side_channels. default is 0
                images inputted and rotated than vertical flip if needed, than detect the fame shift
                :param number: int,
                :return:
                """
                self.times = get_times(self.dir, self.fov_name, self.channels)
                im, _ = get_im_time(os.path.join(self.dir, self.fov_name, 'phase', self.times['phase'][0]))
                im, _ = rotate_fov(np.expand_dims(im, axis=0), crop=False)
                im = rangescale(im.squeeze(), rescale=(0, 1))
                self.template_frame = im
                firstframe = np.expand_dims(np.expand_dims(cv2.resize(im.squeeze(), (512, 512)), axis=0), axis=3)
                # using expand_dims to get it into a shape that the chambers id unet accepts
                # Find chambers, filter results, get bounding boxes:
                chambermask = model_chambers.predict(firstframe, verbose=0)
                chambermask = cv2.resize(np.squeeze(chambermask), im.shape)  # scaling back to original size
                chambermask = postprocess(chambermask,
                                          min_size=min_chamber_area)  # Binarization, cleaning and area filtering
                self.chamberboxes = getChamberBoxes(np.squeeze(chambermask))

                print(f"[{self.fov_name}] -> detect {len(self.chamberboxes)} chambers.")
                border = int(im.shape[0] * 0.02)
                chambercorbox = dict(xtl=min(self.chamberboxes, key=lambda elem: elem['xtl'])['xtl'],
                                     xbr=max(self.chamberboxes, key=lambda elem: elem['xbr'])['xbr'],
                                     ytl=min(self.chamberboxes, key=lambda elem: elem['ytl'])['ytl'] - border,
                                     ybr=max(self.chamberboxes, key=lambda elem: elem['ybr'])['ybr'] + border
                                     )
                v_m = vertical_mean(cropbox(self.template_frame, chambercorbox))

                # image vertical flip if chamber out let in the upside.
                if np.mean(v_m[0:(len(v_m) // 2)]) >= np.mean(v_m[(len(v_m) // 2):]):
                    self.chamber_direction = 0
                    self.chambermask = chambermask[::-1, :]
                    self.chamberboxes = getChamberBoxes(self.chambermask)
                    self.drifttemplate = getDriftTemplate(self.chamberboxes, im.squeeze()[::-1, :])
                else:
                    self.chamber_direction = 1
                    self.chambermask = chambermask
                    self.drifttemplate = getDriftTemplate(self.chamberboxes, im.squeeze())
                return None

            def detect_frameshift(self):
                """
                This function used to detect frame shift.
                :return:
                """
                print(f'[{self.fov_name}] -> loading phase images. \n')
                self.phase_ims = np.zeros((len(self.times['phase']),) + self.template_frame.shape)
                self.time_points['phase'] = [False] * len(self.times['phase'])
                self.rotation = [None] * len(self.times['phase'])

                def parallel_input(fn, inx):
                    im, tp = get_im_time(os.path.join(self.dir, self.fov_name, 'phase', fn))
                    im, angl = rotate_fov(np.expand_dims(im, axis=0), crop=False)
                    if self.chamber_direction == 0:
                        im = im[:, ::-1, :]
                    self.phase_ims[inx, ...] = rangescale(im.squeeze(), (0, 1))
                    self.time_points['phase'][inx] = tp
                    self.rotation[inx] = angl
                    return None

                # --------------------- input all phase images --------------------------------------
                _ = Parallel(n_jobs=30, require='sharedmem')(
                    delayed(parallel_input)(fn, i) for i, fn in enumerate(tqdm(self.times['phase'])))

                print(f'[{self.fov_name}] -> ims shape is {self.phase_ims.shape}.')
                # --------------------- input all phase images --------------------------------------
                driftcorbox = dict(xtl=0,
                                   xbr=None,
                                   ytl=0,
                                   ybr=max(self.chamberboxes, key=lambda elem: elem['ytl'])['ytl']
                                   )  # Box to match template
                self.phase_ims, self.drift_values = driftcorr(self.phase_ims,
                                                              template=self.drifttemplate, box=driftcorbox)
                xcorr_one = int(self.drift_values[0][0])
                ycorr_one = int(self.drift_values[1][0])
                for box in self.chamberboxes:  # TODO: frame shift have bug.
                    box['xtl'] -= xcorr_one
                    box['xbr'] -= xcorr_one
                    box['ytl'] -= ycorr_one
                    box['ybr'] -= ycorr_one

                # -------------detect whether chambers were loaded with cells--------
                num_time = len(self.times['phase'])
                sample_index = np.random.choice(range(num_time), int(num_time * 0.01 + 1))
                selected_ims = self.phase_ims[sample_index, ...]

                chamber_graylevel = []
                chamber_frq = []
                for box in self.chamberboxes:
                    half_chambers = selected_ims[:, box['ytl']:int((box['ybr'] - box['ytl']) / 2 + box['ytl']),
                                    box['xtl']:box['xbr']]
                    mean_chamber = np.mean(half_chambers)
                    chamber_graylevel.append(mean_chamber)
                    sg, frq = image_conv(
                        np.expand_dims(selected_ims[0, int(box['ytl'] + (box['ybr'] - box['ytl']) * 0.20):int(
                            (box['ybr'] - box['ytl']) * 0.6 + box['ytl']),
                                       box['xtl']:box['xbr']], axis=0))
                    chamber_frq.append([sg, frq])
                cells_threshold = np.min(chamber_graylevel) + np.ptp(chamber_graylevel) * 0.6
                chamber_loaded = [True if value < cells_threshold else False for value in chamber_graylevel]
                self.index_of_loaded_chamber = list(np.where(chamber_loaded)[0])
                self.loaded_chamber_box = [self.chamberboxes[index] for index in self.index_of_loaded_chamber]

                fig_sg, ax = plt.subplots(1, 1)
                for i in range(len(chamber_frq)):
                    sg, frq = chamber_frq[i]
                    if i in self.index_of_loaded_chamber:
                        ax.plot(frq, np.log(abs(sg)), '--k', alpha=0.2)
                    else:
                        ax.plot(frq, np.log(abs(sg)), '-r')

                try:
                    fig_sg_ps = os.path.join(self.dir, 'chamber_load')
                    os.makedirs(fig_sg_ps)
                except FileExistsError:
                    pass

                plt.savefig(os.path.join(fig_sg_ps, f'{self.fov_name}_F.svg'), format='svg')
                plt.close()

                fig_ch, ax = plt.subplots(1, 1)
                colors = [self.colors_2[1] if i in self.index_of_loaded_chamber else self.colors_2[0]
                          for i in range(len(chamber_frq))]
                draw_channel_order(rangescale(self.phase_ims[0, ...], (0, 255)).astype(np.uint8),
                                   self.chamberboxes, colors, ax=ax)
                plt.savefig(os.path.join(fig_sg_ps, f'{self.fov_name}_chamber.png'), format='png')
                plt.close()



                self.chamber_graylevel = chamber_graylevel
                # print(f'[{self.fov_name}] -> , chamber_graylevel)
                print(f'[{self.fov_name}] -> detect loaded chamber number: {len(self.loaded_chamber_box)}.')

            def cell_detection(self):
                seg_inputs = ()
                for m, chamberbox in enumerate(self.loaded_chamber_box):
                    if chamberbox:
                        sub_inputs, ori_chn_imgs = parallel_seg_input(self.phase_ims, chamberbox)
                        seg_inputs += (sub_inputs,)
                        self.chamber_phase_ims[f'ch_{self.index_of_loaded_chamber[m]}'] = ori_chn_imgs
                seg_inputs = np.concatenate(seg_inputs, axis=0)
                del self.phase_ims  # release memory
                seg_inputs = np.expand_dims(np.array(seg_inputs), axis=3)
                self.chamber_seg = seg_inputs
                # Format into 4D tensor
                # Run segmentation U-Net:
                seg = model_seg.predict(seg_inputs)
                self.cell_mask = postprocess(seg[:, :, :, 0], min_size=self.cell_minisize)

                # -------------- reform the size-------------- TODO: parallel 1
                def parallel_rearange_mask(t, chn):
                    frame_index = t + chn * len(self.times['phase'])
                    ori_frames[t] = cv2.resize(self.cell_mask[frame_index], ori_frames.shape[2:0:-1])

                for m, box in enumerate(self.loaded_chamber_box):
                    ori_frames = np.empty(
                        [len(self.times['phase']), box['ybr'] - box['ytl'], box['xbr'] - box['xtl']]).astype(
                        np.uint16)

                    # rerange_mask = [dask.delayed(parallel_rearange_mask)(t, m) for t in range(len(self.times['phase']))]
                    # _ = dask.compute(*rerange_mask)

                    _ = Parallel(n_jobs=64, require='sharedmem')(delayed(parallel_rearange_mask)(t, m)
                                                                 for t in range(len(self.times['phase'])))

                    self.chamber_cells_mask[f'ch_{self.index_of_loaded_chamber[m]}'] = ori_frames
                # -------------- get cells contour ------------
                self.loaded_chamber_name = list(self.chamber_cells_mask.keys())
                for channel in self.loaded_chamber_name:
                    contours_list = []
                    for time_mask in self.chamber_cells_mask[channel]:
                        contours = cv2.findContours((time_mask > 0).astype(np.uint8),
                                                    cv2.RETR_EXTERNAL,
                                                    cv2.CHAIN_APPROX_SIMPLE)[0]  # Get contours of single cells
                        contours.sort(key=lambda elem: np.max(elem[:, 0, 1]))  # Sort along Y axis
                        contours_list.append(contours)
                    self.chamber_cells_contour[channel] = contours_list

            def extract_mother_cells_features(self):
                # TODO: bug: when channel have no cells, the features results are strange.
                green_channels = dict()
                red_channels = dict()
                green_time_points = dict()
                red_time_points = dict()

                def parallel_flur_seg(inx_t, time):
                    """
                    get all fluorescent images from disk and seg into channel XX_channels is a dictionary keys are file
                    names and their elements are lists containing chambers ordered by loaded chamber in
                    self.loaded_chamber_name.
                    """
                    if 'green' in self.channels:
                        if time in self.times['green']:
                            drift_valu = (self.drift_values[0][inx_t], self.drift_values[1][inx_t])
                            green_im, time_point = get_fluo_channel(
                                os.path.join(self.dir, self.fov_name, 'green', time),
                                drift_valu, self.rotation[inx_t][0],
                                self.chamber_direction)
                            green_im = back_corrt(green_im.astype(np.float64))  # fluorescence background correct
                            green_channels[time] = [cropbox(green_im, cb) for cb in self.loaded_chamber_box]
                            green_time_points[time] = time_point

                    if 'red' in self.channels:
                        if time in self.times['red']:
                            drift_valu = (self.drift_values[0][inx_t], self.drift_values[1][inx_t])
                            red_im, time_point = get_fluo_channel(os.path.join(self.dir, self.fov_name, 'red', time),
                                                                  drift_valu, self.rotation[inx_t][0],
                                                                  self.chamber_direction)
                            red_im = back_corrt(red_im.astype(np.float64))
                            red_channels[time] = [cropbox(red_im, cb) for cb in self.loaded_chamber_box]
                            red_time_points[time] = time_point
                    return time

                _ = Parallel(n_jobs=128, require='sharedmem')(delayed(parallel_flur_seg)(inx_t, time)
                                                              for inx_t, time in enumerate(tqdm(self.times['phase'])))

                if 'green' in self.channels:
                    self.time_points['green'] = [green_time_points[i] for i in self.times['green']]
                if 'red' in self.channels:
                    self.time_points['red'] = [red_time_points[i] for i in self.times['red']]

                for cha_name_inx, chambername in enumerate(self.loaded_chamber_name):
                    self.mother_cell_pars[chambername] = []
                    for tm_inx, time in enumerate(self.times['phase']):
                        cell_mask = np.zeros(self.chamber_cells_mask[chambername].shape[1:], np.uint8)
                        if self.chamber_cells_contour[chambername][tm_inx]:
                            mother_cell_contour = self.chamber_cells_contour[chambername][tm_inx][0]
                            cell_mask = cv2.drawContours(cell_mask, [mother_cell_contour], 0, 255, -1)
                            rotrect = cv2.minAreaRect(mother_cell_contour)
                            cell_pars = dict(
                                length=max(rotrect[1]),
                                width=min(rotrect[1]),
                                area=cv2.contourArea(mother_cell_contour),
                                time_point=self.time_points['phase'][tm_inx]
                            )
                            if 'green' in self.channels:
                                if time in self.times['green']:
                                    green_channel_im = green_channels[time][cha_name_inx]
                                    green_pixels = green_channel_im[cell_mask == 255]
                                    # cell_pars['green_mean'] = cv2.mean(green_channel_im, cell_mask)[0]
                                    cell_pars['green_mean'] = np.mean(green_pixels)
                                    # medium only consider the medium of the brightest 10% pixels.
                                    cell_pars['green_medium'] = np.quantile(green_pixels, 0.95)
                            if 'red' in self.channels:
                                if time in self.times['red']:
                                    red_channel_im = red_channels[time][cha_name_inx]
                                    red_pixels = red_channel_im[cell_mask == 255]
                                    # cell_pars['red_mean'] = cv2.mean(red_channel_im, cell_mask)[0]
                                    cell_pars['red_mean'] = np.mean(red_pixels)
                                    # medium only consider the medium of the brightest 10% pixels.
                                    cell_pars['red_medium'] = np.quantile(red_pixels, 0.95)
                            self.mother_cell_pars[chambername].append(cell_pars)
                # This section was used to rearrange the single chamber frame along time.
                if 'green' in self.channels:
                    for chamber_index, cham_name in enumerate(self.loaded_chamber_name):
                        imgsize = (len(self.times['green']),) + green_channels[self.times['green'][0]][
                            chamber_index].shape
                        green_chamber_ims = np.empty(imgsize).astype(np.uint16)
                        for t_index, time in enumerate(self.times['green']):
                            green_chamber_ims[t_index] = green_channels[time][chamber_index]
                        self.chamber_green_ims[cham_name] = green_chamber_ims
                if 'red' in self.channels:
                    for chamber_index, cham_name in enumerate(self.loaded_chamber_name):
                        imgsize = (len(self.times['red']),) + red_channels[self.times['red'][0]][chamber_index].shape
                        red_chamber_ims = np.empty(imgsize).astype(np.uint16)
                        for t_index, time in enumerate(self.times['red']):
                            red_chamber_ims[t_index] = red_channels[time][chamber_index]
                        self.chamber_red_ims[cham_name] = red_chamber_ims

            def parse_mother_cell_data(self):
                """
                parse all statistics data into one frame.
                :return:
                """
                pf_list = []
                for chna in self.loaded_chamber_name:  # drop channels don't have cells.
                    if self.mother_cell_pars[chna]:
                        pf = pd.DataFrame(data=self.mother_cell_pars[chna])
                        time = [float(t.split(',')[-1]) for t in pf['time_point']]
                        pf['time_s'] = time
                        pf['chamber'] = [f'{self.fov_name}_{chna}'] * len(pf)
                        pf_list.append(pf)
                self.dataframe_mother_cells = pd.concat(pf_list, sort=False)
                self.dataframe_mother_cells.index = pd.Index(range(len(self.dataframe_mother_cells)))
                return None

            def dump_data(self, compress=True):
                print(f"[{self.fov_name}] -> dump memory data.\n")
                self.dataframe_mother_cells.to_csv(os.path.join(self.dir, self.fov_name + '_statistic.csv'))
                save_data = dict(directory=self.dir,
                                 fov_name=self.fov_name,
                                 frame_rotation_anle=self.rotation,
                                 frame_shift=self.drift_values,
                                 times=self.times,
                                 time_points=self.time_points,
                                 light_channels=self.channels,
                                 chamber_box=self.chamberboxes,
                                 chamber_loaded_name=self.loaded_chamber_name,
                                 chamber_loaded_index=self.index_of_loaded_chamber,
                                 chamber_grayvalue=self.chamber_graylevel,
                                 chamber_direction=self.chamber_direction,
                                 chamber_cells_mask=self.chamber_cells_mask,
                                 chamber_cells_contour=self.chamber_cells_contour,
                                 chamber_phase_images=self.chamber_phase_ims,
                                 mother_cells_parameters=self.mother_cell_pars,
                                 mother_cells_dataframe=self.dataframe_mother_cells
                                 )
                if 'green' in self.channels:
                    save_data['chamber_green_images'] = self.chamber_green_ims
                if 'red' in self.channels:
                    save_data['chamber_red_images'] = self.chamber_red_ims
                if compress:
                    dump(save_data, os.path.join(self.dir, self.fov_name + '.jl'), compress='lz4')
                return None

            def process_flow_GPU(self):
                print(f'[{self.fov_name}] -> detect channels.\n')
                self.detect_channels()
                print(f'[{self.fov_name}] -> detect frameshift.\n')
                self.detect_frameshift()
                print(f'[{self.fov_name}] -> detect cells.\n')
                self.cell_detection()

            def process_flow_CPU(self):
                print(f"[{self.fov_name}] -> extract cells' features.\n")
                self.extract_mother_cells_features()
                print(f"[{self.fov_name}] -> get mother cells data.\n")
                self.parse_mother_cell_data()
                self.dump_data()
                return None

        def get_fovs_name(dir, all_fov=False):
            """
            Get fovs name under dir, if fovs in dir have been treated (i.e. having a memory obj in folder dir), these fovs will
            not returned.
            :param dir: str, ps
            :param all_fov: bool, if True, return all folders, default, False.
            :return: list
            """
            DIR = dir
            jl_file = [jl_name.split('.')[0] for jl_name in os.listdir(DIR) if jl_name.split('.')[-1] == 'jl']
            fov_folder = [folder for folder in os.listdir(DIR)
                          if (folder.split('_')[0] == 'fov' and os.path.isdir(os.path.join(DIR, folder)))]
            if all_fov == False:
                untreated = list(set(fov_folder) - set(jl_file))
                untreated.sort(key=lambda name: int(name.split('_')[-1]))
                fovs_name = [MomoFov(folder, DIR) for folder in untreated]
                return fovs_name
            else:
                fov_folder.sort(key=lambda name: int(name.split('_')[-1]))
                return fov_folder

        def image_conv(imas):
            chamber_im = imas
            len_im = chamber_im.shape[-2]
            v_means = []
            for i in range(len(chamber_im)):
                v_means.append(vertical_mean(chamber_im[i]))

            conv_sg = np.ones(len_im)
            for vm in v_means:
                vm = (vm - np.mean(vm)) / np.std(vm)
                conv_sg = conv_sg * fft(vm)

            freq = fftfreq(len_im, 1 / len_im)
            mask = freq > 0
            return conv_sg[mask], freq[mask]








        def convert_time(time):
            h, s = divmod(time, 60 * 60)
            m, s = divmod(s, 60)
            h = h + m / 60 + s / 3600
            return h




        def paral_read_csv(ps):
            return pd.read_csv(os.path.join(DIR, ps))


        def thread_dump(obj: MomoFov, thread_init: int) -> None:
            obj.process_flow_CPU()
            exitthread[thread_init] = True
            return None

        if __name__ == '__main__':
            DIR = self.file_path
            fov_name = get_fovs_name(DIR)
            fov_num = len(fov_name)
            exitthread = [False] * fov_num
            init = 0

            while fov_name:
                to_process = fov_name.pop(0)
                self.textBrowser2_print(f'Processing {init + 1}/{fov_num}')
                to_process.process_flow_GPU()
                thread.start_new_thread(thread_dump, (to_process, init))
                init += 1

            del to_process
            while False in exitthread:
                time.sleep(5)

            all_scv_name = [file for file in os.listdir(DIR) if
                            (file.split('.')[-1] == 'csv' and file.split('_')[0] == 'fov')]
            all_scv = [dask.delayed(paral_read_csv)(ps) for ps in all_scv_name]
            with ProgressBar():
                al_df = dask.compute(*all_scv, scheduler='threads')
            cells_dict = {}
            self.textBrowser2_print('Dump dictionary of mothercell data.')
            for df in tqdm(al_df):
                cells_name = list(set(df['chamber']))
                for na in cells_name:
                    cells_df = df[df['chamber'] == na]
                    cells_df = cells_df[cells_df['area'] > 100]
                    cells_df['time_h'] = [convert_time(s) for s in cells_df['time_s'] - min(cells_df['time_s'])]
                    cells_dict.update({na: cells_df})

            dump(cells_dict, os.path.join(DIR, 'mothers_raw_dic.jl'), compress='lz4')

            self.textBrowser2_print('Finished!')


            self.chamberdict = cells_dict
            del cells_dict
            self.celllist = al_df
            for i in range(0, len(self.celllist)):
                self.comboBox.addItem(str(i))

            del al_df


if __name__ == "__main__":
    app=QApplication(sys.argv)
    myWin = MyMainForm()
    myWin.show()
    sys.exit(app.exec_())

